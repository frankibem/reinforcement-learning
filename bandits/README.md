## Bandit Algorithms
K-armed bandit problems are often used to introduce reinforcement learning as they expose several underlying concepts like value functions (state and action-value), epoch-greedy methods for action-selection, balancing exploration and exploitation and so on. The code samples here are implementations of problems described in chapter 2 of [1]. The recommended order for going through the samples is:
1. simple bandit
2. non-stationary bandit
3. upper confidence bound
4. gradient bandit

## References
1. Richard S. Sutton, Andrew G. Barto (1998). Reinforcement Learning: An Introduction. MIT Press.
