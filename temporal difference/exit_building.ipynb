{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## The Exit Building Problem\n",
    "In this problem, there are 6 rooms and our agent starts out in a random room. The doors between rooms can be bidirectional or directional. All transitions between rooms give 0 reward except transitions to room 5 (terminal state) which gives a reward of 100. The objective is to learn a sequence of steps to take us to the exit (room 5). Naturally, the problem can be modelled using a directed graph as shown below. We apply Q-learning to learn action-values and solve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc38b3fec18>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJQAAAD8CAYAAACRm43jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDM3O4xpy9wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc38b3fec50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mpimg.imread('exit_building.png');\n",
    "plt.axis('off')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class BuildingEnv:\n",
    "    def __init__(self):\n",
    "        self.nS = 6  # no. of states\n",
    "        self.nA = 6  # no. of actions\n",
    "        \n",
    "        # A[s] is a list of actions that can be taken from state s\n",
    "        A = {}\n",
    "        A[0] = [4]\n",
    "        A[1] = [3, 5]\n",
    "        A[2] = [3]\n",
    "        A[3] = [1, 4]\n",
    "        A[4] = [0, 3, 5]\n",
    "        A[5] = [5]\n",
    "        self.A = A\n",
    "        \n",
    "        # Holds all possible transitions for states in the environment\n",
    "        # T[s][a] is a (s', r, done) tuple\n",
    "        # You will receive reward r and transition to state s' if you take\n",
    "        # action a while currently in state s. Done is true if you have\n",
    "        # reached the exit        \n",
    "        T = {}\n",
    "        exit = self.nS - 1\n",
    "        for s in range(self.nS):\n",
    "            T[s] = {}\n",
    "            for a in A[s]:\n",
    "                reward = 100 if a == exit else 0\n",
    "                done = True if a == exit else False\n",
    "                T[s][a] = ((a, reward, done))\n",
    "        self.T = T\n",
    "\n",
    "        \n",
    "    # Resets the environment and returns the initial state\n",
    "    def reset(self):\n",
    "        # s is the current state\n",
    "        self.s = np.random.choice(self.nS, 1)[0]\n",
    "        return self.s\n",
    "        \n",
    "    # Executes the given action in the current state and returns\n",
    "    # (s', r, done) which means you will receive reward r and transition to\n",
    "    # state s' if you execute action in the current state, s. Done is true if\n",
    "    # you have reached the exit\n",
    "    def step(self, action):\n",
    "        if not action in self.A[self.s]:\n",
    "            raise ValueError('Cannot execute action %d in state %d' % (action, self.s))\n",
    "        \n",
    "        # Update the state based on the action taken\n",
    "        obs = self.T[self.s][action]\n",
    "        self.s = obs[0]\n",
    "        \n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def q_learning(env, discount_factor = 1, num_episodes=100):\n",
    "    '''\n",
    "    Evaluates a policy given an environment. Assumes equiprobable selection of actions\n",
    "    Args:\n",
    "        env: Represents the dynamics of the environment\n",
    "        discount_factor: smaller values favor instantaneous reward, larger values are far-sighted\n",
    "        num_episodes: the maximum number of episodes to run\n",
    "        all (s,a) pairs.\n",
    "    '''\n",
    "    Q = np.zeros((env.nS, env.nA))\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            # Select random action from set of all actions that can be taken from this state\n",
    "            a = np.random.choice(env.A[s])\n",
    "            \n",
    "            # Execute the action and receive next state and reward\n",
    "            s_, r, done = env.step(a)\n",
    "            \n",
    "            # Update Q(s,a) based on possible actions that can be taken from next state\n",
    "            action_values = [Q[s_,a_] for a_ in env.A[s_]]\n",
    "            Q[s,a] = r + discount_factor * np.max(action_values)\n",
    "                \n",
    "            # Go to next state\n",
    "            s = s_\n",
    "        \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.    0.    0.    0.  100.    0.]\n",
      " [   0.    0.    0.   50.    0.  200.]\n",
      " [   0.    0.    0.   50.    0.    0.]\n",
      " [   0.  100.    0.    0.  100.    0.]\n",
      " [  50.    0.    0.   50.    0.  200.]\n",
      " [   0.    0.    0.    0.    0.  200.]]\n"
     ]
    }
   ],
   "source": [
    "env = BuildingEnv()\n",
    "Q = q_learning(env, discount_factor=0.5, num_episodes=500)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Since we use a random policy to learn the action-values, we run the environment several times to ensure that most transitions are executed. The task is also episodic (eventually ends, as opposed to continuous) and I have used a discount factor of 0.5. You can experiment with different values.\n",
    "\n",
    "The results are what we expect. The best (and only) move to take from 0 is to go to 4. The best move from 1 is to go directly to 5 (notice how we can also go to 3, but that has less value). From 3, going to 1 or 4 has equal value (so we could pick randomly) and so on. \n",
    "\n",
    "Here is an example run to see how an agent can make decisions using these action-values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 -> 3 -> 1 -> 5\n"
     ]
    }
   ],
   "source": [
    "s = env.reset()\n",
    "states = []\n",
    "done = False\n",
    "while not done:\n",
    "    states.append(s)\n",
    "    action = np.argmax(Q[s])\n",
    "    s_, r, done = env.step(action)\n",
    "        \n",
    "    s = s_\n",
    "states.append(s)\n",
    "print(\" -> \".join([str(s) for s in states]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Although we learned the values of actions, we can also use Q-learning to learn the values of states. At each step, we would then select action that takes us to the state with the highest value. The GridWorld problem in Example 4.1 of [1] can be modeled and solved in a similar fashion.\n",
    "\n",
    "## References\n",
    "1. Richard S. Sutton, Andrew G. Barto (1998). Reinforcement Learning: An Introduction. MIT Press."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
